{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import combine_state_for_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/NFS_SHARE/home/b.krzepkowski/miniconda3/envs/clpi_env/lib/python3.10/site-packages/torch/_functorch/deprecated.py:105: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.combine_state_for_ensemble is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.stack_module_state instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('combine_state_for_ensemble', 'torch.func.stack_module_state')\n"
     ]
    }
   ],
   "source": [
    "num_models = 5\n",
    "batch_size = 64\n",
    "in_features, out_features = 3, 3\n",
    "models = [torch.nn.Linear(in_features, out_features) for i in range(num_models)]\n",
    "models = torch.nn.ModuleList(models)\n",
    "data = torch.randn(batch_size, in_features)\n",
    "\n",
    "fmodel, params, buffers = combine_state_for_ensemble(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.3537e-01, -9.3838e-01,  1.1049e+00],\n",
       "         [ 3.5752e-01, -3.8763e-01,  2.9125e-02],\n",
       "         [ 3.1324e-02,  2.0464e-01, -4.6318e-01],\n",
       "         [ 1.6353e+00, -2.1415e+00,  1.9226e+00],\n",
       "         [ 6.4341e-01, -5.9127e-02, -4.7478e-01],\n",
       "         [ 3.6864e-01, -1.2428e-01,  5.2799e-02],\n",
       "         [ 1.3743e-01,  2.4515e-01, -4.8676e-01],\n",
       "         [ 1.1643e+00, -1.4507e+00,  1.0270e+00],\n",
       "         [-3.4014e-01, -3.9560e-01,  6.1466e-02],\n",
       "         [ 2.2788e-01, -6.5528e-02, -2.5136e-01],\n",
       "         [ 9.9512e-01, -1.0088e+00,  1.1434e+00],\n",
       "         [-8.9788e-02, -2.0068e-01, -6.4784e-02],\n",
       "         [ 2.1838e-01,  5.4761e-01, -8.0977e-01],\n",
       "         [-4.7253e-01, -2.3612e-01, -5.5369e-01],\n",
       "         [-3.2030e-01, -2.1204e-01, -4.0943e-01],\n",
       "         [ 1.5899e-01, -9.0495e-01,  4.6136e-01],\n",
       "         [ 1.5484e-01, -2.0304e-01, -4.9482e-01],\n",
       "         [ 8.2865e-01, -5.1465e-01,  2.2109e-01],\n",
       "         [-3.7296e-01, -8.6942e-02,  5.7748e-01],\n",
       "         [-3.1449e-01,  4.1611e-01, -6.6583e-01],\n",
       "         [ 6.5745e-02,  2.8908e-01, -4.2654e-01],\n",
       "         [ 8.9394e-01, -8.7208e-01,  9.3430e-01],\n",
       "         [ 8.4872e-01, -1.1048e+00,  1.2818e+00],\n",
       "         [ 1.8134e+00, -1.5817e+00,  1.6434e+00],\n",
       "         [ 3.4437e-01, -4.3022e-01,  1.8572e-01],\n",
       "         [ 1.0236e+00, -7.9223e-01,  1.3523e+00],\n",
       "         [ 6.4866e-01, -1.4763e+00,  9.0719e-01],\n",
       "         [ 7.5983e-01, -4.1735e-01, -4.2642e-01],\n",
       "         [ 4.9072e-01, -6.4730e-01,  6.5491e-01],\n",
       "         [ 3.5928e-01, -4.7681e-01, -9.2236e-02],\n",
       "         [ 2.4859e-01, -7.4860e-01,  7.9404e-01],\n",
       "         [ 1.3310e+00, -1.4667e+00,  1.5950e+00],\n",
       "         [ 5.7805e-01, -7.3456e-01,  7.4735e-01],\n",
       "         [-8.6246e-01,  5.5160e-01, -5.9854e-01],\n",
       "         [ 8.7569e-01, -1.3486e+00,  1.0569e+00],\n",
       "         [ 7.3359e-01, -6.9246e-01,  6.0900e-01],\n",
       "         [ 1.0681e-01, -3.8958e-01,  3.3383e-01],\n",
       "         [ 7.4895e-01, -1.2061e-01,  1.2234e-01],\n",
       "         [ 3.1951e-01, -6.6148e-01,  4.7713e-01],\n",
       "         [ 3.2898e-01, -4.1713e-01,  3.2072e-01],\n",
       "         [-2.4145e-01,  8.8709e-02, -8.7546e-01],\n",
       "         [ 7.0870e-01, -6.1491e-01,  9.1657e-01],\n",
       "         [ 3.6927e-01, -3.8098e-01,  1.6303e-01],\n",
       "         [ 3.5263e-01, -7.0958e-01,  5.1741e-01],\n",
       "         [ 3.4000e-01, -1.1256e+00,  1.0793e+00],\n",
       "         [ 1.6771e-01, -4.6010e-01, -5.6611e-02],\n",
       "         [-4.1601e-01, -3.3770e-01, -2.4020e-01],\n",
       "         [-4.6347e-01,  3.1231e-01, -5.8222e-01],\n",
       "         [ 1.0650e+00, -4.8677e-01,  5.5674e-01],\n",
       "         [ 1.1733e-01,  7.1754e-02,  7.4088e-02],\n",
       "         [ 2.9598e-01, -2.8818e-01,  6.0839e-02],\n",
       "         [ 3.4438e-01, -6.1895e-01,  5.3480e-01],\n",
       "         [-6.1969e-01,  8.5772e-01, -8.7138e-01],\n",
       "         [ 1.0542e+00, -9.1901e-01,  1.0375e+00],\n",
       "         [ 4.5371e-01,  4.4572e-01, -5.6159e-01],\n",
       "         [ 4.6422e-01, -2.4370e-01,  4.3581e-01],\n",
       "         [ 5.6523e-01, -6.8513e-01,  3.0575e-01],\n",
       "         [ 4.0409e-01, -9.6650e-01,  6.0176e-01],\n",
       "         [ 7.1698e-02,  6.2003e-01, -6.1099e-01],\n",
       "         [-5.7112e-02, -3.2415e-01,  1.0467e-01],\n",
       "         [ 4.4400e-01,  3.8346e-02,  1.3518e-01],\n",
       "         [ 9.5736e-03, -3.9660e-01,  3.4729e-01],\n",
       "         [-9.1236e-02, -2.2253e-01, -1.0731e-01],\n",
       "         [ 4.9578e-02,  1.8996e-01, -4.4682e-01]],\n",
       "\n",
       "        [[-5.1023e-01, -3.4167e-01, -4.0991e-01],\n",
       "         [-4.4429e-02, -5.5682e-01,  6.6055e-02],\n",
       "         [ 3.3067e-01,  3.2918e-01,  6.2440e-01],\n",
       "         [-8.9420e-01, -2.3264e+00, -1.4468e+00],\n",
       "         [ 5.6765e-01, -3.2606e-01,  4.7501e-01],\n",
       "         [ 2.5269e-01,  3.0738e-01,  3.8775e-01],\n",
       "         [ 4.6636e-01,  4.4636e-01,  6.9915e-01],\n",
       "         [-5.2954e-01, -1.8808e+00, -8.6092e-01],\n",
       "         [-6.5227e-01, -7.3712e-01, -1.3121e-01],\n",
       "         [ 2.0073e-01, -8.2703e-02,  3.8122e-01],\n",
       "         [-1.9329e-01, -3.5389e-01, -3.6306e-01],\n",
       "         [-2.2242e-01, -2.7454e-01,  1.5538e-01],\n",
       "         [ 8.7139e-01,  8.4919e-01,  1.0433e+00],\n",
       "         [-5.8221e-01, -1.3533e+00, -5.3816e-02],\n",
       "         [-4.2744e-01, -9.8065e-01,  3.5044e-02],\n",
       "         [-7.8692e-01, -1.4736e+00, -5.5424e-01],\n",
       "         [-8.6094e-03, -9.5720e-01,  1.6569e-01],\n",
       "         [ 2.1805e-01, -4.7445e-01,  6.7448e-02],\n",
       "         [-3.5073e-01,  1.1130e+00,  2.9467e-01],\n",
       "         [ 2.6821e-01,  5.2905e-01,  7.5733e-01],\n",
       "         [ 4.5197e-01,  6.6627e-01,  7.3967e-01],\n",
       "         [-1.2750e-01, -3.2379e-01, -2.5333e-01],\n",
       "         [-4.2597e-01, -4.5602e-01, -5.0098e-01],\n",
       "         [-1.2511e-01, -1.0168e+00, -7.6196e-01],\n",
       "         [-1.0464e-01, -4.2039e-01,  3.1090e-02],\n",
       "         [ 6.4772e-02,  6.9276e-01, -6.9385e-02],\n",
       "         [-9.9822e-01, -2.3260e+00, -1.0485e+00],\n",
       "         [ 2.7515e-01, -1.3212e+00,  8.3707e-02],\n",
       "         [-2.2350e-01, -2.3370e-01, -1.2988e-01],\n",
       "         [-1.3860e-01, -1.0454e+00, -5.5625e-02],\n",
       "         [-5.4411e-01, -3.7994e-01, -3.0035e-01],\n",
       "         [-4.1260e-01, -8.9006e-01, -7.6287e-01],\n",
       "         [-2.4537e-01, -3.1760e-01, -1.9884e-01],\n",
       "         [-5.4843e-02,  9.0161e-01,  7.7758e-01],\n",
       "         [-6.6601e-01, -1.5987e+00, -8.1412e-01],\n",
       "         [-6.3780e-02, -3.8050e-01, -1.2302e-01],\n",
       "         [-2.6628e-01, -1.0788e-01,  3.3136e-02],\n",
       "         [ 5.8197e-01,  5.5550e-01,  5.0544e-01],\n",
       "         [-3.8322e-01, -6.3969e-01, -2.1629e-01],\n",
       "         [-1.0557e-01, -1.4901e-01,  5.9531e-02],\n",
       "         [-2.3921e-02, -8.3309e-01,  3.5859e-01],\n",
       "         [-4.9939e-03,  3.8941e-01,  1.7861e-03],\n",
       "         [-2.9107e-02, -2.9916e-01,  9.4093e-02],\n",
       "         [-4.0800e-01, -7.0912e-01, -2.5978e-01],\n",
       "         [-8.8213e-01, -1.0281e+00, -6.9119e-01],\n",
       "         [-2.8525e-01, -9.8947e-01, -8.3781e-02],\n",
       "         [-6.4951e-01, -1.1058e+00, -1.2060e-01],\n",
       "         [ 2.5632e-02,  3.0652e-01,  6.0248e-01],\n",
       "         [ 4.4624e-01,  2.6916e-01,  2.0805e-01],\n",
       "         [ 2.5107e-01,  8.7825e-01,  5.5633e-01],\n",
       "         [ 1.1019e-02, -2.1074e-01,  1.7233e-01],\n",
       "         [-3.1626e-01, -3.9927e-01, -1.5123e-01],\n",
       "         [ 4.9227e-01,  1.4524e+00,  1.1769e+00],\n",
       "         [-4.2850e-02, -2.4132e-01, -2.5255e-01],\n",
       "         [ 9.5817e-01,  1.0362e+00,  1.0171e+00],\n",
       "         [ 1.9835e-01,  6.3238e-01,  3.1906e-01],\n",
       "         [-1.9566e-01, -9.3743e-01, -1.9866e-01],\n",
       "         [-6.4603e-01, -1.3460e+00, -5.4299e-01],\n",
       "         [ 8.2172e-01,  1.3765e+00,  1.1148e+00],\n",
       "         [-3.3194e-01, -3.5348e-01,  3.7681e-02],\n",
       "         [ 4.9391e-01,  9.7997e-01,  6.1376e-01],\n",
       "         [-3.5759e-01, -1.3580e-01, -3.1447e-04],\n",
       "         [-2.4692e-01, -4.1712e-01,  1.2343e-01],\n",
       "         [ 3.3003e-01,  3.1755e-01,  6.1387e-01]],\n",
       "\n",
       "        [[-6.6570e-01,  8.0601e-01, -8.2880e-02],\n",
       "         [ 2.4470e-02,  8.5019e-01,  4.0657e-01],\n",
       "         [-1.7316e-01, -1.0054e-01,  1.1566e+00],\n",
       "         [ 9.3432e-01,  2.9932e+00, -1.5701e+00],\n",
       "         [ 1.2282e+00,  6.5089e-01,  8.4731e-01],\n",
       "         [ 7.6289e-02,  5.3895e-02,  8.7182e-01],\n",
       "         [ 1.0567e-01, -1.8654e-01,  1.2431e+00],\n",
       "         [ 7.9224e-01,  2.3742e+00, -8.4155e-01],\n",
       "         [-1.6469e+00,  8.5551e-01,  2.3511e-01],\n",
       "         [ 4.1171e-02,  3.5028e-01,  8.2118e-01],\n",
       "         [ 3.6584e-01,  9.3032e-01, -7.7009e-02],\n",
       "         [-9.0478e-01,  4.7256e-01,  5.8304e-01],\n",
       "         [ 6.5355e-01, -5.7493e-01,  1.6589e+00],\n",
       "         [-1.3526e+00,  1.3308e+00,  2.3986e-01],\n",
       "         [-1.1256e+00,  1.0365e+00,  3.7416e-01],\n",
       "         [-9.4116e-01,  1.6989e+00, -3.6563e-01],\n",
       "         [ 7.2655e-02,  1.1183e+00,  4.7261e-01],\n",
       "         [ 9.2872e-01,  9.0562e-01,  3.7694e-01],\n",
       "         [-2.1514e+00, -8.1364e-01,  9.5777e-01],\n",
       "         [-7.5754e-01, -3.8913e-01,  1.3580e+00],\n",
       "         [-1.1125e-01, -4.0112e-01,  1.3245e+00],\n",
       "         [ 3.4888e-01,  8.5643e-01,  5.2882e-02],\n",
       "         [-1.2529e-01,  1.0049e+00, -2.2461e-01],\n",
       "         [ 1.7162e+00,  1.7916e+00, -6.7066e-01],\n",
       "         [-1.6091e-01,  7.3704e-01,  3.9050e-01],\n",
       "         [ 2.7646e-01, -1.1555e-02,  3.8341e-01],\n",
       "         [-3.1200e-01,  2.6523e+00, -1.0578e+00],\n",
       "         [ 1.3914e+00,  1.6064e+00,  2.7765e-01],\n",
       "         [-2.9608e-01,  6.4796e-01,  2.3362e-01],\n",
       "         [ 1.2610e-01,  1.2909e+00,  2.0660e-01],\n",
       "         [-1.0139e+00,  7.4085e-01,  5.3876e-02],\n",
       "         [ 6.4890e-01,  1.5546e+00, -6.0917e-01],\n",
       "         [-1.9334e-01,  7.5618e-01,  1.4039e-01],\n",
       "         [-2.0838e+00, -8.5737e-01,  1.4836e+00],\n",
       "         [ 1.0452e-01,  2.0473e+00, -7.2465e-01],\n",
       "         [ 3.0951e-01,  8.3679e-01,  1.9741e-01],\n",
       "         [-8.5059e-01,  4.0654e-01,  4.5970e-01],\n",
       "         [ 9.0556e-01, -7.8785e-02,  9.9777e-01],\n",
       "         [-5.3444e-01,  9.6518e-01,  9.8804e-02],\n",
       "         [-3.2121e-01,  4.9593e-01,  4.6141e-01],\n",
       "         [-4.4898e-01,  8.6929e-01,  7.3124e-01],\n",
       "         [-2.3100e-02,  1.4929e-01,  4.4361e-01],\n",
       "         [-7.2196e-02,  6.2812e-01,  4.7258e-01],\n",
       "         [-5.0309e-01,  1.0417e+00,  3.9623e-02],\n",
       "         [-1.1349e+00,  1.3936e+00, -4.6268e-01],\n",
       "         [-3.5445e-01,  1.1974e+00,  2.0237e-01],\n",
       "         [-1.5320e+00,  1.1477e+00,  1.9981e-01],\n",
       "         [-1.2049e+00, -2.0926e-01,  1.1753e+00],\n",
       "         [ 1.1746e+00,  3.0734e-01,  6.1221e-01],\n",
       "         [-4.9862e-01, -5.3280e-01,  1.1562e+00],\n",
       "         [-1.3180e-01,  5.1801e-01,  5.7501e-01],\n",
       "         [-5.2230e-01,  7.5419e-01,  2.0035e-01],\n",
       "         [-1.2019e+00, -1.3393e+00,  1.9645e+00],\n",
       "         [ 6.2031e-01,  8.2878e-01,  5.1029e-02],\n",
       "         [ 9.5554e-01, -6.6645e-01,  1.6367e+00],\n",
       "         [-7.9688e-02, -1.8454e-01,  8.3742e-01],\n",
       "         [ 1.9932e-01,  1.2815e+00,  5.1850e-02],\n",
       "         [-5.0790e-01,  1.6534e+00, -3.5759e-01],\n",
       "         [ 1.3574e-01, -1.0778e+00,  1.8245e+00],\n",
       "         [-1.0092e+00,  5.7134e-01,  4.4387e-01],\n",
       "         [ 2.0576e-01, -5.4330e-01,  1.2020e+00],\n",
       "         [-1.0930e+00,  4.1081e-01,  4.2909e-01],\n",
       "         [-8.7231e-01,  5.9997e-01,  5.2864e-01],\n",
       "         [-1.4826e-01, -8.3704e-02,  1.1421e+00]],\n",
       "\n",
       "        [[-1.9240e-02,  1.0429e+00,  6.8081e-01],\n",
       "         [ 6.8362e-01,  4.4073e-01, -4.8342e-02],\n",
       "         [ 1.1002e+00,  1.8312e-01, -3.1296e-01],\n",
       "         [-4.0018e-01,  1.5486e+00,  1.2798e+00],\n",
       "         [ 1.4230e+00,  2.5618e-01, -1.6155e-01],\n",
       "         [ 9.3605e-01,  5.1440e-01,  1.2832e-01],\n",
       "         [ 1.2449e+00,  2.0057e-01, -2.5668e-01],\n",
       "         [ 1.0491e-01,  1.0247e+00,  6.4053e-01],\n",
       "         [ 1.6863e-02,  3.0366e-01, -3.7984e-01],\n",
       "         [ 9.5869e-01,  3.0324e-01, -1.7920e-01],\n",
       "         [ 3.2915e-01,  1.1549e+00,  9.0918e-01],\n",
       "         [ 4.7512e-01,  3.2138e-01, -2.5294e-01],\n",
       "         [ 1.7109e+00,  7.9033e-02, -3.2904e-01],\n",
       "         [ 2.4284e-01, -8.0724e-02, -9.0101e-01],\n",
       "         [ 3.6083e-01,  4.9609e-02, -6.8200e-01],\n",
       "         [-1.3056e-01,  5.5917e-01, -6.1641e-02],\n",
       "         [ 8.3869e-01,  1.0367e-01, -5.1029e-01],\n",
       "         [ 9.3955e-01,  6.4018e-01,  2.8935e-01],\n",
       "         [ 1.1305e-01,  6.8842e-01,  2.3610e-01],\n",
       "         [ 1.0443e+00,  2.2939e-02, -5.4812e-01],\n",
       "         [ 1.2005e+00,  2.3200e-01, -2.1488e-01],\n",
       "         [ 4.3194e-01,  1.0293e+00,  7.5034e-01],\n",
       "         [ 5.7476e-02,  1.1892e+00,  9.0231e-01],\n",
       "         [ 3.8604e-01,  1.5314e+00,  1.4424e+00],\n",
       "         [ 5.8064e-01,  5.2769e-01,  5.9317e-02],\n",
       "         [ 4.9380e-01,  1.3396e+00,  1.2320e+00],\n",
       "         [-3.6040e-01,  8.2837e-01,  2.5705e-01],\n",
       "         [ 1.1761e+00,  2.3627e-01, -2.6349e-01],\n",
       "         [ 3.5997e-01,  8.1062e-01,  4.2557e-01],\n",
       "         [ 6.3972e-01,  3.4537e-01, -2.0569e-01],\n",
       "         [-5.9955e-03,  8.2287e-01,  3.6761e-01],\n",
       "         [ 6.2043e-02,  1.4176e+00,  1.2192e+00],\n",
       "         [ 3.2871e-01,  8.6993e-01,  5.0219e-01],\n",
       "         [ 6.4158e-01, -2.7982e-02, -6.9065e-01],\n",
       "         [-7.6287e-02,  1.0010e+00,  5.7803e-01],\n",
       "         [ 5.5778e-01,  8.2620e-01,  4.8299e-01],\n",
       "         [ 3.5062e-01,  5.7694e-01,  9.2507e-02],\n",
       "         [ 1.2708e+00,  6.4409e-01,  3.8581e-01],\n",
       "         [ 2.4450e-01,  6.5697e-01,  1.7285e-01],\n",
       "         [ 5.3531e-01,  6.1239e-01,  1.7844e-01],\n",
       "         [ 8.6923e-01, -1.6316e-01, -8.8301e-01],\n",
       "         [ 5.0924e-01,  1.0316e+00,  7.8676e-01],\n",
       "         [ 6.5777e-01,  5.2942e-01,  7.9970e-02],\n",
       "         [ 2.1674e-01,  6.7956e-01,  1.9798e-01],\n",
       "         [-3.7017e-01,  9.4312e-01,  4.5195e-01],\n",
       "         [ 4.6596e-01,  3.2867e-01, -2.6228e-01],\n",
       "         [ 9.8246e-02,  1.0838e-01, -6.5257e-01],\n",
       "         [ 7.8047e-01,  2.0357e-02, -6.0918e-01],\n",
       "         [ 1.0778e+00,  9.1109e-01,  7.2281e-01],\n",
       "         [ 8.8138e-01,  5.1359e-01,  1.3077e-01],\n",
       "         [ 7.1048e-01,  4.6827e-01,  5.0264e-03],\n",
       "         [ 2.8940e-01,  7.0807e-01,  2.6081e-01],\n",
       "         [ 1.2454e+00, -8.0880e-02, -6.3404e-01],\n",
       "         [ 5.0330e-01,  1.1203e+00,  8.9662e-01],\n",
       "         [ 1.7533e+00,  2.6673e-01, -4.7440e-02],\n",
       "         [ 7.8850e-01,  7.5237e-01,  4.4806e-01],\n",
       "         [ 5.0570e-01,  5.9847e-01,  1.3290e-01],\n",
       "         [-6.1622e-03,  6.8952e-01,  1.5250e-01],\n",
       "         [ 1.5792e+00,  1.8739e-01, -1.8657e-01],\n",
       "         [ 3.3393e-01,  4.0944e-01, -1.5662e-01],\n",
       "         [ 1.1338e+00,  6.1803e-01,  3.3231e-01],\n",
       "         [ 2.4920e-01,  5.6223e-01,  5.0858e-02],\n",
       "         [ 4.6673e-01,  2.8951e-01, -3.0378e-01],\n",
       "         [ 1.0980e+00,  1.9441e-01, -2.9754e-01]],\n",
       "\n",
       "        [[-4.5825e-01,  3.1695e-01,  4.8281e-01],\n",
       "         [-5.0113e-01, -1.9982e-01,  5.1575e-02],\n",
       "         [-2.1190e-01, -3.9460e-01, -4.2863e-01],\n",
       "         [-8.6914e-01,  8.7915e-01,  9.2370e-01],\n",
       "         [-1.7540e-01, -1.5465e-01, -7.7457e-01],\n",
       "         [-1.1227e-01, -1.8397e-02, -4.4459e-01],\n",
       "         [-9.9480e-02, -3.1589e-01, -6.3742e-01],\n",
       "         [-7.9856e-01,  3.7403e-01,  5.8141e-01],\n",
       "         [-9.5967e-01, -6.4552e-01,  9.9584e-01],\n",
       "         [-3.1996e-01, -2.8271e-01, -2.7009e-01],\n",
       "         [-2.2289e-01,  6.0587e-01, -2.1120e-02],\n",
       "         [-6.0151e-01, -4.4806e-01,  3.4539e-01],\n",
       "         [ 1.6845e-01, -2.9968e-01, -1.1946e+00],\n",
       "         [-1.2210e+00, -1.0547e+00,  1.0705e+00],\n",
       "         [-9.9288e-01, -8.4143e-01,  7.7907e-01],\n",
       "         [-1.0768e+00, -3.4890e-01,  1.1214e+00],\n",
       "         [-7.1624e-01, -5.7869e-01,  1.4845e-01],\n",
       "         [-2.3858e-01,  1.6665e-01, -4.1146e-01],\n",
       "         [-2.2173e-01, -1.3231e-01,  3.3041e-01],\n",
       "         [-2.7976e-01, -6.3451e-01, -2.8320e-01],\n",
       "         [-4.7902e-02, -2.9627e-01, -6.3792e-01],\n",
       "         [-2.3474e-01,  4.7898e-01, -6.8575e-02],\n",
       "         [-3.6600e-01,  5.4491e-01,  3.0764e-01],\n",
       "         [-1.5004e-01,  1.1439e+00, -2.4075e-01],\n",
       "         [-4.6882e-01, -1.2794e-01,  9.9254e-02],\n",
       "         [ 2.3124e-01,  8.9628e-01, -5.1166e-01],\n",
       "         [-1.2570e+00, -6.4649e-02,  1.3577e+00],\n",
       "         [-5.6444e-01, -2.5955e-01, -3.0084e-01],\n",
       "         [-3.7180e-01,  1.5695e-01,  1.5308e-01],\n",
       "         [-7.0175e-01, -3.3442e-01,  2.4596e-01],\n",
       "         [-5.8598e-01,  2.9855e-02,  6.2003e-01],\n",
       "         [-3.4496e-01,  8.6002e-01,  2.1637e-01],\n",
       "         [-3.7530e-01,  2.2519e-01,  1.6500e-01],\n",
       "         [-4.1594e-01, -8.7114e-01,  1.9074e-01],\n",
       "         [-8.3112e-01,  2.6405e-01,  7.7738e-01],\n",
       "         [-3.0103e-01,  2.5987e-01, -7.9014e-02],\n",
       "         [-4.7679e-01, -1.6076e-01,  3.0183e-01],\n",
       "         [ 1.9262e-01,  2.8324e-01, -9.8409e-01],\n",
       "         [-6.2034e-01, -8.5649e-02,  4.6219e-01],\n",
       "         [-3.7442e-01, -3.8787e-02,  5.6156e-02],\n",
       "         [-8.2041e-01, -9.2458e-01,  2.7041e-01],\n",
       "         [-1.2771e-02,  4.9836e-01, -2.7684e-01],\n",
       "         [-3.9819e-01, -9.7269e-02, -1.6142e-02],\n",
       "         [-6.3919e-01, -6.5231e-02,  4.9217e-01],\n",
       "         [-8.6604e-01,  5.7702e-02,  1.0905e+00],\n",
       "         [-7.8425e-01, -4.2734e-01,  4.6325e-01],\n",
       "         [-1.1234e+00, -8.6560e-01,  1.0837e+00],\n",
       "         [-4.7050e-01, -7.3894e-01,  7.9370e-02],\n",
       "         [ 1.7390e-01,  5.6768e-01, -8.8002e-01],\n",
       "         [ 5.3481e-03, -5.3073e-02, -4.6544e-01],\n",
       "         [-3.8380e-01, -1.5948e-01, -5.4051e-02],\n",
       "         [-5.0755e-01, -4.5393e-03,  3.3493e-01],\n",
       "         [-2.1888e-03, -7.1137e-01, -6.0595e-01],\n",
       "         [-1.2633e-01,  6.2708e-01, -2.3069e-01],\n",
       "         [ 3.4374e-01, -3.6449e-02, -1.4021e+00],\n",
       "         [ 3.1269e-02,  2.3299e-01, -4.7253e-01],\n",
       "         [-5.9818e-01, -5.2999e-02,  2.2498e-01],\n",
       "         [-9.0790e-01, -1.2806e-01,  8.6029e-01],\n",
       "         [ 2.9812e-01, -2.1879e-01, -1.1868e+00],\n",
       "         [-6.4267e-01, -3.8559e-01,  4.7314e-01],\n",
       "         [ 2.1725e-01,  1.8501e-01, -8.6343e-01],\n",
       "         [-5.4319e-01, -2.2036e-01,  4.4141e-01],\n",
       "         [-6.6013e-01, -4.9096e-01,  3.9937e-01],\n",
       "         [-2.0959e-01, -3.8021e-01, -4.3165e-01]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.func import functional_call, vmap, grad\n",
    "output = vmap(fmodel, (0, None, None))(params, buffers, data)\n",
    "output.shape\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch._functorch.make_functional.FunctionalModuleWithBuffers"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionalModuleWithBuffers(\n",
       "  (stateless_model): Linear(in_features=3, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(..., device='meta', size=(64, 3), grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta = torch.randn(batch_size, in_features, device=\"meta\")\n",
    "fmodel.stateless_model(data_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (64) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [64, 3].  Tensor sizes: [3, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fmodel(params[\u001b[39m0\u001b[39;49m], buffers, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/clpi_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clpi_env/lib/python3.10/site-packages/torch/_functorch/make_functional.py:304\u001b[0m, in \u001b[0;36mFunctionalModuleWithBuffers.forward\u001b[0;34m(self, params, buffers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m old_state \u001b[39m=\u001b[39m _swap_state(\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateless_model,\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_names_map,\n\u001b[1;32m    301\u001b[0m     \u001b[39mtuple\u001b[39m(params) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(buffers),\n\u001b[1;32m    302\u001b[0m )\n\u001b[1;32m    303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstateless_model(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[39m# Remove the loaded state on self.stateless_model\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     _swap_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateless_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_names_map, old_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/clpi_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clpi_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (64) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [64, 3].  Tensor sizes: [3, 3]"
     ]
    }
   ],
   "source": [
    "fmodel(params[0], buffers, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d[0] = torch.randn(3, 3)\n",
    "d[1] = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = zip(*d.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1),\n",
       " (tensor([[-0.6299,  1.6704, -0.7502],\n",
       "          [-0.3051, -0.7545, -0.8502],\n",
       "          [ 0.8492, -1.1000,  1.3581]]),\n",
       "  tensor([[ 2.1257,  0.3285,  0.3972],\n",
       "          [ 0.3498, -0.3261, -0.3731],\n",
       "          [ 1.7074, -0.0045, -0.3956]])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mtensor(\u001b[39mlist\u001b[39;49m(d\u001b[39m.\u001b[39;49mitems()))\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(list(d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clpi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
